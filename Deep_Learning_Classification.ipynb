{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie score</th>\n",
       "      <th>budget</th>\n",
       "      <th>gross</th>\n",
       "      <th>runtime</th>\n",
       "      <th>votes</th>\n",
       "      <th>star avg score</th>\n",
       "      <th>director avg score</th>\n",
       "      <th>writer avg score</th>\n",
       "      <th>genre avg score</th>\n",
       "      <th>rating avg score</th>\n",
       "      <th>country avg score</th>\n",
       "      <th>company avg score</th>\n",
       "      <th>Total Awards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.1</td>\n",
       "      <td>30000000</td>\n",
       "      <td>31743332</td>\n",
       "      <td>79</td>\n",
       "      <td>117268</td>\n",
       "      <td>6.864286</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>6.746931</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.839474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>35000000</td>\n",
       "      <td>81159365</td>\n",
       "      <td>123</td>\n",
       "      <td>201705</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>5.957143</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.756322</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.315741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1500000</td>\n",
       "      <td>779820</td>\n",
       "      <td>102</td>\n",
       "      <td>11945</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.687004</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.660602</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>40000000</td>\n",
       "      <td>95001343</td>\n",
       "      <td>128</td>\n",
       "      <td>71006</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>7.040390</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.384354</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>13000000</td>\n",
       "      <td>16574731</td>\n",
       "      <td>93</td>\n",
       "      <td>28791</td>\n",
       "      <td>6.440000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.715720</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie score    budget     gross  runtime   votes  star avg score  \\\n",
       "0          7.1  30000000  31743332       79  117268        6.864286   \n",
       "1          6.8  35000000  81159365      123  201705        6.875000   \n",
       "2          5.0   1500000    779820      102   11945        5.900000   \n",
       "3          7.5  40000000  95001343      128   71006        7.500000   \n",
       "4          5.8  13000000  16574731       93   28791        6.440000   \n",
       "\n",
       "   director avg score  writer avg score  genre avg score  rating avg score  \\\n",
       "0            7.100000          7.100000         6.746931          6.254035   \n",
       "1            5.957143          6.200000         6.756322          6.254035   \n",
       "2            5.666667          5.666667         5.687004          6.453213   \n",
       "3            6.740000          6.630000         7.040390          6.254035   \n",
       "4            5.800000          5.800000         6.715720          6.453213   \n",
       "\n",
       "   country avg score  company avg score  Total Awards  \n",
       "0           6.216790           6.839474           0.0  \n",
       "1           6.216790           6.315741           0.0  \n",
       "2           6.660602           5.000000           0.0  \n",
       "3           6.216790           6.384354           0.0  \n",
       "4           6.216790           5.800000           0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film = pd.read_csv('Resources/clean_genre.csv')\n",
    "film = film.drop('Unnamed: 0', axis = 1)\n",
    "film = film.drop('Total Nominations', axis =1)\n",
    "film.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nancymathur/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie score</th>\n",
       "      <th>budget</th>\n",
       "      <th>gross</th>\n",
       "      <th>runtime</th>\n",
       "      <th>votes</th>\n",
       "      <th>star avg score</th>\n",
       "      <th>director avg score</th>\n",
       "      <th>writer avg score</th>\n",
       "      <th>genre avg score</th>\n",
       "      <th>rating avg score</th>\n",
       "      <th>country avg score</th>\n",
       "      <th>company avg score</th>\n",
       "      <th>Award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.1</td>\n",
       "      <td>30000000</td>\n",
       "      <td>31743332</td>\n",
       "      <td>79</td>\n",
       "      <td>117268</td>\n",
       "      <td>6.864286</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>6.746931</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.839474</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>35000000</td>\n",
       "      <td>81159365</td>\n",
       "      <td>123</td>\n",
       "      <td>201705</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>5.957143</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.756322</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.315741</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1500000</td>\n",
       "      <td>779820</td>\n",
       "      <td>102</td>\n",
       "      <td>11945</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.687004</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.660602</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>40000000</td>\n",
       "      <td>95001343</td>\n",
       "      <td>128</td>\n",
       "      <td>71006</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>7.040390</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.384354</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>13000000</td>\n",
       "      <td>16574731</td>\n",
       "      <td>93</td>\n",
       "      <td>28791</td>\n",
       "      <td>6.440000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.715720</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.7</td>\n",
       "      <td>65000000</td>\n",
       "      <td>210614939</td>\n",
       "      <td>117</td>\n",
       "      <td>648211</td>\n",
       "      <td>6.530000</td>\n",
       "      <td>7.057143</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>6.106086</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.384354</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>99603</td>\n",
       "      <td>110</td>\n",
       "      <td>14114</td>\n",
       "      <td>6.610000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>7.225000</td>\n",
       "      <td>6.715720</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.660602</td>\n",
       "      <td>6.796296</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.8</td>\n",
       "      <td>25000000</td>\n",
       "      <td>71985628</td>\n",
       "      <td>104</td>\n",
       "      <td>226504</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>6.780000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>5.687004</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>5.726316</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>5979011</td>\n",
       "      <td>95</td>\n",
       "      <td>3154</td>\n",
       "      <td>7.029412</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>6.715720</td>\n",
       "      <td>6.453213</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>5.340000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.8</td>\n",
       "      <td>200000000</td>\n",
       "      <td>166112167</td>\n",
       "      <td>158</td>\n",
       "      <td>303766</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>6.227273</td>\n",
       "      <td>5.766667</td>\n",
       "      <td>6.106086</td>\n",
       "      <td>6.254035</td>\n",
       "      <td>6.216790</td>\n",
       "      <td>6.315741</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie score     budget      gross  runtime   votes  star avg score  \\\n",
       "0          7.1   30000000   31743332       79  117268        6.864286   \n",
       "1          6.8   35000000   81159365      123  201705        6.875000   \n",
       "2          5.0    1500000     779820      102   11945        5.900000   \n",
       "3          7.5   40000000   95001343      128   71006        7.500000   \n",
       "4          5.8   13000000   16574731       93   28791        6.440000   \n",
       "5          7.7   65000000  210614939      117  648211        6.530000   \n",
       "6          6.2          0      99603      110   14114        6.610000   \n",
       "7          6.8   25000000   71985628      104  226504        6.615385   \n",
       "8          5.8          0    5979011       95    3154        7.029412   \n",
       "9          5.8  200000000  166112167      158  303766        6.615385   \n",
       "\n",
       "   director avg score  writer avg score  genre avg score  rating avg score  \\\n",
       "0            7.100000          7.100000         6.746931          6.254035   \n",
       "1            5.957143          6.200000         6.756322          6.254035   \n",
       "2            5.666667          5.666667         5.687004          6.453213   \n",
       "3            6.740000          6.630000         7.040390          6.254035   \n",
       "4            5.800000          5.800000         6.715720          6.453213   \n",
       "5            7.057143          6.666667         6.106086          6.453213   \n",
       "6            7.250000          7.225000         6.715720          6.453213   \n",
       "7            6.780000          6.800000         5.687004          6.254035   \n",
       "8            5.800000          5.750000         6.715720          6.453213   \n",
       "9            6.227273          5.766667         6.106086          6.254035   \n",
       "\n",
       "   country avg score  company avg score Award  \n",
       "0           6.216790           6.839474    No  \n",
       "1           6.216790           6.315741    No  \n",
       "2           6.660602           5.000000    No  \n",
       "3           6.216790           6.384354    No  \n",
       "4           6.216790           5.800000    No  \n",
       "5           6.216790           6.384354    No  \n",
       "6           6.660602           6.796296    No  \n",
       "7           6.216790           5.726316    No  \n",
       "8           6.216790           5.340000    No  \n",
       "9           6.216790           6.315741    No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film = film.rename(columns = {\"Total Awards\":\"Award\"})\n",
    "\n",
    "film['Award'].loc[film['Award'] >= 1] = \"Yes\"\n",
    "film['Award'].loc[film['Award'] == 0] = \"No\"\n",
    "\n",
    "film.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6820, 12) (6820,)\n"
     ]
    }
   ],
   "source": [
    "X = film.drop(\"Award\", axis=1)\n",
    "y = film[\"Award\"]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=18, activation='relu', input_dim=12))\n",
    "model.add(Dense(units=18, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 38        \n",
      "=================================================================\n",
      "Total params: 614\n",
      "Trainable params: 614\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5115 samples\n",
      "Epoch 1/60\n",
      "5115/5115 - 1s - loss: 0.3417 - accuracy: 0.9441\n",
      "Epoch 2/60\n",
      "5115/5115 - 0s - loss: 0.2060 - accuracy: 0.9449\n",
      "Epoch 3/60\n",
      "5115/5115 - 0s - loss: 0.1858 - accuracy: 0.9449\n",
      "Epoch 4/60\n",
      "5115/5115 - 0s - loss: 0.1767 - accuracy: 0.9449\n",
      "Epoch 5/60\n",
      "5115/5115 - 0s - loss: 0.1716 - accuracy: 0.9449\n",
      "Epoch 6/60\n",
      "5115/5115 - 0s - loss: 0.1684 - accuracy: 0.9449\n",
      "Epoch 7/60\n",
      "5115/5115 - 0s - loss: 0.1660 - accuracy: 0.9449\n",
      "Epoch 8/60\n",
      "5115/5115 - 0s - loss: 0.1647 - accuracy: 0.9449\n",
      "Epoch 9/60\n",
      "5115/5115 - 0s - loss: 0.1638 - accuracy: 0.9449\n",
      "Epoch 10/60\n",
      "5115/5115 - 0s - loss: 0.1641 - accuracy: 0.9449\n",
      "Epoch 11/60\n",
      "5115/5115 - 0s - loss: 0.1631 - accuracy: 0.9449\n",
      "Epoch 12/60\n",
      "5115/5115 - 0s - loss: 0.1620 - accuracy: 0.9449\n",
      "Epoch 13/60\n",
      "5115/5115 - 0s - loss: 0.1631 - accuracy: 0.9449\n",
      "Epoch 14/60\n",
      "5115/5115 - 0s - loss: 0.1640 - accuracy: 0.9449\n",
      "Epoch 15/60\n",
      "5115/5115 - 0s - loss: 0.1619 - accuracy: 0.9449\n",
      "Epoch 16/60\n",
      "5115/5115 - 0s - loss: 0.1611 - accuracy: 0.9449\n",
      "Epoch 17/60\n",
      "5115/5115 - 0s - loss: 0.1620 - accuracy: 0.9449\n",
      "Epoch 18/60\n",
      "5115/5115 - 0s - loss: 0.1618 - accuracy: 0.9449\n",
      "Epoch 19/60\n",
      "5115/5115 - 0s - loss: 0.1618 - accuracy: 0.9449\n",
      "Epoch 20/60\n",
      "5115/5115 - 0s - loss: 0.1613 - accuracy: 0.9449\n",
      "Epoch 21/60\n",
      "5115/5115 - 0s - loss: 0.1600 - accuracy: 0.9449\n",
      "Epoch 22/60\n",
      "5115/5115 - 0s - loss: 0.1594 - accuracy: 0.9449\n",
      "Epoch 23/60\n",
      "5115/5115 - 0s - loss: 0.1598 - accuracy: 0.9449\n",
      "Epoch 24/60\n",
      "5115/5115 - 0s - loss: 0.1598 - accuracy: 0.9449\n",
      "Epoch 25/60\n",
      "5115/5115 - 0s - loss: 0.1606 - accuracy: 0.9449\n",
      "Epoch 26/60\n",
      "5115/5115 - 0s - loss: 0.1593 - accuracy: 0.9449\n",
      "Epoch 27/60\n",
      "5115/5115 - 0s - loss: 0.1596 - accuracy: 0.9449\n",
      "Epoch 28/60\n",
      "5115/5115 - 0s - loss: 0.1586 - accuracy: 0.9449\n",
      "Epoch 29/60\n",
      "5115/5115 - 0s - loss: 0.1589 - accuracy: 0.9458\n",
      "Epoch 30/60\n",
      "5115/5115 - 0s - loss: 0.1596 - accuracy: 0.9464\n",
      "Epoch 31/60\n",
      "5115/5115 - 0s - loss: 0.1621 - accuracy: 0.9464\n",
      "Epoch 32/60\n",
      "5115/5115 - 0s - loss: 0.1592 - accuracy: 0.9466\n",
      "Epoch 33/60\n",
      "5115/5115 - 0s - loss: 0.1584 - accuracy: 0.9462\n",
      "Epoch 34/60\n",
      "5115/5115 - 0s - loss: 0.1578 - accuracy: 0.9464\n",
      "Epoch 35/60\n",
      "5115/5115 - 0s - loss: 0.1573 - accuracy: 0.9466\n",
      "Epoch 36/60\n",
      "5115/5115 - 0s - loss: 0.1582 - accuracy: 0.9474\n",
      "Epoch 37/60\n",
      "5115/5115 - 0s - loss: 0.1576 - accuracy: 0.9478\n",
      "Epoch 38/60\n",
      "5115/5115 - 0s - loss: 0.1573 - accuracy: 0.9474\n",
      "Epoch 39/60\n",
      "5115/5115 - 0s - loss: 0.1568 - accuracy: 0.9474\n",
      "Epoch 40/60\n",
      "5115/5115 - 0s - loss: 0.1569 - accuracy: 0.9476\n",
      "Epoch 41/60\n",
      "5115/5115 - 0s - loss: 0.1578 - accuracy: 0.9484\n",
      "Epoch 42/60\n",
      "5115/5115 - 0s - loss: 0.1568 - accuracy: 0.9476\n",
      "Epoch 43/60\n",
      "5115/5115 - 0s - loss: 0.1581 - accuracy: 0.9484\n",
      "Epoch 44/60\n",
      "5115/5115 - 0s - loss: 0.1569 - accuracy: 0.9482\n",
      "Epoch 45/60\n",
      "5115/5115 - 0s - loss: 0.1566 - accuracy: 0.9478\n",
      "Epoch 46/60\n",
      "5115/5115 - 0s - loss: 0.1567 - accuracy: 0.9480\n",
      "Epoch 47/60\n",
      "5115/5115 - 0s - loss: 0.1572 - accuracy: 0.9484\n",
      "Epoch 48/60\n",
      "5115/5115 - 0s - loss: 0.1575 - accuracy: 0.9484\n",
      "Epoch 49/60\n",
      "5115/5115 - 0s - loss: 0.1569 - accuracy: 0.9482\n",
      "Epoch 50/60\n",
      "5115/5115 - 0s - loss: 0.1551 - accuracy: 0.9484\n",
      "Epoch 51/60\n",
      "5115/5115 - 0s - loss: 0.1561 - accuracy: 0.9488\n",
      "Epoch 52/60\n",
      "5115/5115 - 0s - loss: 0.1548 - accuracy: 0.9480\n",
      "Epoch 53/60\n",
      "5115/5115 - 0s - loss: 0.1558 - accuracy: 0.9488\n",
      "Epoch 54/60\n",
      "5115/5115 - 0s - loss: 0.1556 - accuracy: 0.9488\n",
      "Epoch 55/60\n",
      "5115/5115 - 0s - loss: 0.1547 - accuracy: 0.9498\n",
      "Epoch 56/60\n",
      "5115/5115 - 0s - loss: 0.1552 - accuracy: 0.9482\n",
      "Epoch 57/60\n",
      "5115/5115 - 0s - loss: 0.1560 - accuracy: 0.9486\n",
      "Epoch 58/60\n",
      "5115/5115 - 0s - loss: 0.1547 - accuracy: 0.9486\n",
      "Epoch 59/60\n",
      "5115/5115 - 0s - loss: 0.1549 - accuracy: 0.9482\n",
      "Epoch 60/60\n",
      "5115/5115 - 0s - loss: 0.1540 - accuracy: 0.9480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3eefcfd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1705/1 - 0s - loss: 0.2270 - accuracy: 0.9390\n",
      "Normal Neural Network - Loss: 0.1845116556914321, Accuracy: 0.9390029311180115\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "film_model = load_model(\"film_model_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['No' 'No' 'No' 'No' 'No']\n",
      "Actual Labels: ['No', 'No', 'No', 'No', 'No']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
